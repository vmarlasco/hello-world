# 5th of July
For the development of the NN and the system in general it han been deduced **three** lines of investigation:

```bash
*NN ---¬
       |> Improve NN 
       |          |----> 1.  Rebuild and optimize the image
       |          |----> 2.  Seek for NN optimization (GPU, libraries)
       |
       |> Train the NN
                  |----> 3.  Change NN classes, only 3 (extinguisher, door, exit sign)
                  |----> 4.  Increase the dataset
                  |----> 5.  Retrain until a better performance

* System performance ¬
                     |-> 6.  Solution with two pipelines
                     |-> 7.  Solution using the 3s and object traking between frames

* New Features ---¬
                   |---> 8.  How to perform object tracking
                   |---> 9.  How to meassure distances between objects
                   |---> 10. How to compute rotation angle
                   |---> 11. How to draw features in the map
       
```

## 7. Swith between object detection and object traking.
The solution is over the facts that:
* We use only 50% of RPi CPU running the NN
* The NN inference time is higly related with the convolutional layers. Because of the poor integration of Tensorflow with RPi, no          GPU is used, what would produce an insane time to process each image: **3 seconds**.
* We have found that OpenCV is more optimized that tensorflow. This fact in conjunction with the reduce processing time of object tracking (compare to object detection) has give us a partial solution: use tracking between detection.

**Benefits:**
* We can achieve a better response time
* It is very usefull for computing angles and distances!!!!

https://www.learnopencv.com/object-tracking-using-opencv-cpp-python/

## Tomorrow:
* Export the model to a freeze version and see the performance of the node
* Create the node for taking images from the camera
* Create the node for translating the images to visualized images
* Train the model
* Implement tracking node

## 6. Two pipelines processing
A partial but not very usefull solution is to use **two pipelines** and **multithreading**. We take advantage of the 50% of the CPU usage to run multiple instances. The problem is that although we can increase the throughput, the latency will remain the same.

![alt text](https://github.com/vmarlasco/hello-world/blob/journalist/journal/07_05/TwoPipeline.png "Two pipeline approach")

## 2. NN optimization
Waiting for professor's answer, the next idea arise: as the paper show, squeezeNet runs faster in OpenCV than in tensorflow, so we will try to freeze (better for deployment) and migrate the model to OpenCV. We will also try to take the photos from a video stream instead of simple photos and seek for an improvement.

![alt text](https://github.com/vmarlasco/hello-world/blob/journalist/journal/07_05/InferenceTime_v00.png "Inference Time")

http://digital.csic.es/bitstream/10261/163973/1/Performance_Analysis_of_Real_Time_DNN_on_RPi.pdf


## 8. Object tracking
https://www.learnopencv.com/object-tracking-using-opencv-cpp-python/

* Use KFC algorithm for general purpose tracking
* Use TLD under occlusion
* Use  MEDIANFLOW for small & predictable motion

http://asus4.hatenablog.com/entry/2017/05/25/_Raspberry_Pi_/_Python3_/_OpenCV3_Tracking_Sample

--------------------- ------------------------------------- ------------------------------------------------------ ------------

https://software.intel.com/en-us/articles/a-closer-look-at-object-detection-recognition-and-tracking

https://programmaticponderings.com/2013/02/09/opencv-and-cvblob-with-raspberry-pi/

https://www.pyimagesearch.com/2015/09/14/ball-tracking-with-opencv/

https://www.pyimagesearch.com/2015/05/25/basic-motion-detection-and-tracking-with-python-and-opencv/

## 9. Angle measure
https://diganthp.github.io/pi-vision/




