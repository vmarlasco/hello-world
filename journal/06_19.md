# 19th June
It has been implemented the detector node in ROS. The code may look simething like this:

```python
#!/usr/bin/env python
# Author: Victor Martinez

# Future-type libraries
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

# Tool libraries
import sys
import cv2
import numpy as np
import tensorflow as tf
import time

# Detector libraries
from .util import bbox_transform, draw_box
from .config import base_model_config
from .roe_squeezeDet_config import roe_squeezeDet_config
from .squeezeDet import SqueezeDet

# Raspberry Camera libraries
from picamera.array import PiRGBArray
from picamera import PiCamera


# ROS libraries
import rospy
from std_msgs.msg import String
from sensor_msgs.msg import Image
from cv_bridge import CvBridge, CvBridgeError

############################################ LABELS ###########################
FLAGS = tf.app.flags.FLAGS

#base_dir = "/src/NN"
base_dir = "/media/victor/DATA/MEGA/THESIS/SOFTWARE/Docker/Files/NN"

tf.app.flags.DEFINE_string(
    'checkpoint', base_dir + '/data/model_checkpoints/model.ckpt-20000',
    """Path to the model parameter file.""")


class RoeDetector():
    """docstring for ClassName"""
    def __init__(self):

        ##### Initializing the neede objects for image capture
        self._bridge = CvBridge()
        self._camera = PiCamera()
        self._camera.resolution = (1280, 720)

        #time.sleep(0.1)     #allow the camera to warmup. Do not needed due time until first capture

        ##### ROS node intialization
        self._image_pub = rospy.Publisher('/ROE/DetectedImage', Image, queue_size=1)
        # TODO(Victor) : Declare another publisher for managing information
        # TODO(Victor) : Declare a subscriber for node control. In this way it could be possible to add pause etc.

        ##### Tensorflow initialization
        self._mc = roe_squeezeDet_config()      #configure squeezenet
        self._mc.BATCH_SIZE = 1
        self._mc.LOAD_PRETRAINED_MODEL = False  #model parameters will be restored from checkpoint
        self._model = SqueezeDet(self._mc)      #loading the net

        self._saver = tf.train.Saver(self._model.model_params)  #Defining the saver

        self._sess = tf.InteractiveSession(config=tf.ConfigProto(allow_soft_placement=True))    #Start interactive session

        self._saver.restore(self._sess, FLAGS.checkpoint)       #Restoring the paremeters from checkpoint

        ##### Utils
        self._cls2clr = {
                    'extinguisher': (255, 191, 0),
                    'exitsign': (0, 191, 255),
                    'lightswitch': (70, 191, 255),
                    'door': (255, 0, 191)
                }


    def _draw_box(im, box_list, label_list, color=(0,255,0), cdict=None, form='center'):
        assert form == 'center' or form == 'diagonal', \
            'bounding box format not accepted: {}.'.format(form)

        for bbox, label in zip(box_list, label_list):

            if form == 'center':
                bbox = bbox_transform(bbox)

            xmin, ymin, xmax, ymax = [int(b) for b in bbox]

            l = label.split(':')[0] # text before "CLASS: (PROB)"
            if cdict and l in cdict:
                c = cdict[l]
            else:
                c = color

            # draw box
            cv2.rectangle(im, (xmin, ymin), (xmax, ymax), c, 1)
            # draw label
            font = cv2.FONT_HERSHEY_SIMPLEX
            cv2.putText(im, label, (xmin, ymax), font, 0.3, c, 1)

    
    def startOperation(self):

        #TODO(Victor) : Manage exceptions with key board interrupt, and other errors and finally to free TF session
        rawCapture = PiRGBArray(self._camera)

        try:    
            while not rospy.is_shutdown():
                #Take a capture
                self._camera.capture(rawCapture, format="bgr")
                im = rawCapture.array
                #im = im.astype(np.float32, copy=False)
                #im = cv2.resize(im, (mc.IMAGE_WIDTH, mc.IMAGE_HEIGHT))
                input_image = im - mc.BGR_MEANS

                #Detection
                det_boxes, det_probs, det_class = sess.run(
                    [model.det_boxes, model.det_probs, model.det_class],
                    feed_dict={model.image_input: [input_image]})

                #Filtering
                final_boxes, final_probs, final_class = model.filter_prediction(
                    det_boxes[0], det_probs[0], det_class[0])

                keep_idx = [idx for idx in range(len(final_probs)) \
                                if final_probs[idx] > mc.PLOT_PROB_THRESH]
                final_boxes = [final_boxes[idx] for idx in keep_idx]
                final_probs = [final_probs[idx] for idx in keep_idx]
                final_class = [final_class[idx] for idx in keep_idx]

                # Draw boxes
                _draw_box(
                    im, final_boxes,
                    [mc.CLASS_NAMES[idx] + ': (%.2f)' % prob \
                     for idx, prob in zip(final_class, final_probs)],
                    cdict=self._cls2clr,
                )

                # output
                try:
                    self._image_pub.publish(self._bridge.cv2_to_imgmsg(im, "bgr8"))
                except CvBridgeError as e:
                    print(e)
                    raise
        except:
            self._sess.close()
            raise

    
    def _callback(self):
        raise NotImplementedError



def main(args=None):
    detector = RoeDetector()
    rospy.init_node('image_detector', anonymous=True)
    print("\n\n ######## STARTING ######")
    try:
        detector.startOperation()
    except KeyboardInterrupt:
        print("\n>>Shutting down :(")
        cv2.destroyAllWindows()

if __name__ == '__main__':
    # TODO(Victor) : whats the better approach for running the program?Â¿
    #main(sys.argv)
    tf.app.run()
```
## FACTS
* All the needed files would be imported without folders, in order to save folder commands in the creation process.
* As **first approach**, the image capture is implemented directly without using *picamera_node* in order to accelerate the process. This is under the assumption that if we save the transport and decompression process, and can be done in the same node it would run faster. We need to **compare** with the other implementation, and see if it is faster due to the OS operation.
* It has been implemented a hierarchical exception handling
* In order to accelerate the performance of the node, when the system is launched, the first tasks are related with object creation and NN initialization, two computationally expensive processes. After that, a loop will read and process each image, so this node **sets the pace**.

## TODOs
* Correct or implement the TODOS indicated in the source code.
* Create a catkin package. The one that has been implemented show errors.
* Compare with the other implementation and launch file
* Compare the detection performance running the code in host directly

## Resources
* Testing exception handling:
```python
#!/usr/bin/env python

import time
import sys

def bucle():
    try:
        while True:
            print("\nHola caracola")
            time.sleep(1)
    except KeyboardInterrupt:
        print("\n\nHandling level 2")
        raise


def main(args=None):
    try:
        bucle()
    except KeyboardInterrupt:
        print("\n\nHandling level 1")
    finally:
        print("\n>>Shutting down :(")

if __name__ == '__main__':
    main(sys.argv)
```
* http://picamera.readthedocs.io/en/release-1.10/api_array.html
* https://github.com/shunchan0677/Tensorflow_in_ROS/blob/master/tensorflow_in_ros_mnist.py
* http://wiki.ros.org/opencv_apps
* http://wiki.ros.org/cv_bridge/Tutorials/ConvertingBetweenROSImagesAndOpenCVImagesPython
* https://www.pyimagesearch.com/2015/03/30/accessing-the-raspberry-pi-camera-with-opencv-and-python/
* https://raspberrypi.stackexchange.com/questions/24262/getting-image-data-from-raspberry-pi-camera-module-in-opencv-with-python
* https://gist.github.com/awesomebytes/e02ad0778dfea1692450
* https://github.com/UbiquityRobotics/raspicam_node
